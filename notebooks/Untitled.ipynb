{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from gechebnet.data.dataloader import get_train_val_data_loaders\n",
    "from gechebnet.engine.engine import create_supervised_evaluator, create_supervised_trainer\n",
    "from gechebnet.engine.utils import prepare_batch, wandb_log\n",
    "from gechebnet.graph.graph import HyperCubeGraph\n",
    "from gechebnet.model.chebnet import ChebNet\n",
    "from gechebnet.model.optimizer import get_optimizer\n",
    "from gechebnet.utils import random_choice\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "from torch.nn import NLLLoss\n",
    "from torch.nn.functional import nll_loss\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATASET = \"MNIST\"\n",
    "VAL_RATIO = 0.2\n",
    "NX1, NX2 = (28, 28)\n",
    "\n",
    "IN_CHANNELS = 1\n",
    "OUT_CHANNELS = 10\n",
    "HIDDEN_CHANNELS = 20\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def get_model(nx3, knn, eps, xi, weight_sigma, weight_kernel, K, pooling):\n",
    "    graphs = [\n",
    "        HyperCubeGraph(\n",
    "            grid_size=(NX1, NX2),\n",
    "            nx3=nx3,\n",
    "            weight_kernel=weight_kernel,\n",
    "            weight_sigma=weight_sigma,\n",
    "            knn=knn,\n",
    "            sigmas=(xi / eps, xi, 1.0),\n",
    "            weight_comp_device=DEVICE,\n",
    "        ),\n",
    "        HyperCubeGraph(\n",
    "            grid_size=(NX1 // 2, NX2 // 2),\n",
    "            nx3=nx3,\n",
    "            weight_kernel=weight_kernel,\n",
    "            weight_sigma=weight_sigma,\n",
    "            knn=knn,\n",
    "            sigmas=(xi / eps, xi, 1.0),\n",
    "            weight_comp_device=DEVICE,\n",
    "        ),\n",
    "        HyperCubeGraph(\n",
    "            grid_size=(NX1 // 2 // 2, NX2 // 2 // 2),\n",
    "            nx3=nx3,\n",
    "            weight_kernel=weight_kernel,\n",
    "            weight_sigma=weight_sigma,\n",
    "            knn=knn,\n",
    "            sigmas=(xi / eps, xi, 1.0),\n",
    "            weight_comp_device=DEVICE,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    model = ChebNet(graphs, K, IN_CHANNELS, OUT_CHANNELS, HIDDEN_CHANNELS, laplacian_device=DEVICE, pooling=pooling)\n",
    "    #while model.capacity < NUM_PARAMS:\n",
    "    #    hidden_channels += 1\n",
    "    #    model = ChebNet(graphs, K, IN_CHANNELS, OUT_CHANNELS, hidden_channels, laplacian_device=DEVICE, pooling=pooling)\n",
    "\n",
    "    print(model.capacity)\n",
    "\n",
    "    return model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "xi = 0.01\n",
    "eps = 0.1\n",
    "K = 20\n",
    "knn = 27\n",
    "learning_rate = 1e-3\n",
    "nx3 = 6\n",
    "optimizer = \"adam\"\n",
    "weight_sigma = 1.\n",
    "weight_decay = 0\n",
    "weight_kernel = \"gaussian\"\n",
    "pooling = \"max\"\n",
    "    \n",
    "train_loader, val_loader = get_train_val_data_loaders(DATASET, batch_size=batch_size, val_ratio=VAL_RATIO, data_path=DATA_PATH)\n",
    "\n",
    "model = get_model(nx3, knn, eps, xi, weight_sigma, weight_kernel, K, pooling)\n",
    "\n",
    "optimizer = get_optimizer(model, optimizer, learning_rate, weight_decay)\n",
    "\n",
    "loss_fn = nll_loss\n",
    "metrics = {\"val_mnist_acc\": Accuracy(), \"val_mnist_loss\": Loss(loss_fn)}\n",
    "\n",
    "# create ignite's engines\n",
    "trainer = create_supervised_trainer(\n",
    "    L=nx3, model=model, optimizer=optimizer, loss_fn=loss_fn, device=DEVICE, prepare_batch=prepare_batch\n",
    ")\n",
    "ProgressBar(persist=False, desc=\"Training\").attach(trainer)\n",
    "\n",
    "ProgressBar(persist=False, desc=\"Training\").attach(trainer)\n",
    "\n",
    "evaluator = create_supervised_evaluator(L=nx3, model=model, metrics=metrics, device=DEVICE, prepare_batch=prepare_batch)\n",
    "\n",
    "# track training with wandb\n",
    "_ = trainer.add_event_handler(Events.EPOCH_COMPLETED, wandb_log, evaluator, val_loader)\n",
    "\n",
    "# save best model\n",
    "\n",
    "trainer.run(train_loader, max_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "output = loss(m(input), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(10)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gechebnet.model.convolution import cheb_conv, ChebConv\n",
    "from gechebnet.model.chebnet import ChebNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChebNet(\n",
    "[HyperCubeGraph(\n",
    "            grid_size=(2, 2),\n",
    "            nx3=2,\n",
    "            weight_kernel=\"gaussian\",\n",
    "            weight_sigma=1.,\n",
    "            knn=2,\n",
    "            sigmas=(xi / eps, xi, 1.0),\n",
    "            weight_comp_device=DEVICE,\n",
    "        )],\n",
    "    10, 1, 10, 20\n",
    ")\n",
    "\n",
    "model.capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 0.01\n",
    "eps = 0.1\n",
    "\n",
    "graph = HyperCubeGraph(\n",
    "            grid_size=(2, 2),\n",
    "            nx3=2,\n",
    "            weight_kernel=\"gaussian\",\n",
    "            weight_sigma=1.,\n",
    "            knn=2,\n",
    "            sigmas=(xi / eps, xi, 1.0),\n",
    "            weight_comp_device=DEVICE,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, 2, 8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(2, 2, 3)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheb_conv(graph.laplacian, x, w).permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(-1/(2*(0.1)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = ChebConv(graph, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, 2, 8)\n",
    "C(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 1, 2, 2)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "B, C, H, W = x.shape  # (B, C, H, W)\n",
    "\n",
    "x = x.unsqueeze(2).expand(B, C, 2, 2, 2).reshape(B, C, -1)  # (B, C, L*H*W)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(B, C, -1, H, W)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
