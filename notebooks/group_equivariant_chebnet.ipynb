{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gechebnet.model.chebnet import ChebNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 7\n",
    "nx3 =  6\n",
    "input_dim = 1\n",
    "output_dim = 10\n",
    "hidden_dim = 16\n",
    "edge_red = \"max\"\n",
    "net = ChebNet(K, nx3, input_dim, output_dim, hidden_dim, edge_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_param = 10000\n",
    "hidden_dim = 1\n",
    "model = ChebNet(K, nx3, input_dim, output_dim, hidden_dim, edge_red)\n",
    "while model.capacity < num_param:\n",
    "    hidden_dim += 1\n",
    "    model = ChebNet(K, nx3, input_dim, output_dim, hidden_dim+1, edge_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_field(graph_data, node_idx)\n",
    "    \"\"\"\n",
    "    [summary]\n",
    "    \"\"\"\n",
    "\n",
    "    neighbors, weights = get_neighbors(graph_data, node_idx)\n",
    "\n",
    "    point_cloud = torch.zeros(len(neighbors), 4)\n",
    "    point_cloud[:, 0] = graph_data.node_pos[neighbors, 0]\n",
    "\n",
    "    im = ax.scatter(\n",
    "        graph_data.node_pos[neighbors, 0], graph_data.node_pos[neighbors, 1], graph_data.node_pos[neighbors, 2], c=weights, s=50, alpha=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10*hidden_dim + 4 * (hidden_dim*hidden_dim*K + hidden_dim) + input_dim*hidden_dim*K + hidden_dim + hidden_dim*output_dim*K + output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"gechebnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download mnist and rotated mnist\n",
    "data_path = \"data\"\n",
    "mnist_processed_path = download_mnist(data_path)\n",
    "rotated_mnist_processed_path = download_rotated_mnist(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the graph embedding data\n",
    "eps = .25\n",
    "xi = .01\n",
    "nx1, nx2, nx3 = (28, 28, 6)\n",
    "graph_data = GraphData(grid_size=(nx1, nx2), \n",
    "                       num_layers=nx3,\n",
    "                       static_compression=(\"edge\", 0.5),\n",
    "                       self_loop=True, \n",
    "                       weight_threshold=0.3, \n",
    "                       sigma=1., \n",
    "                       lambdas=((xi/eps), xi, 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training dataloader from mnist\n",
    "train_mnist_loader = get_dataloader(\n",
    "    get_datalist_mnist(graph_data, mnist_processed_path, train=True), \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test dataloader from mnist\n",
    "test_mnist_loader = get_dataloader(\n",
    "    get_datalist_mnist(graph_data, mnist_processed_path, train=False), \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test dataloader from rotated mnist\n",
    "test_rotated_mnist_loader = get_dataloader(\n",
    "    get_datalist_rotated_mnist(graph_data, rotated_mnist_processed_path, train=False), \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"chebnet\"\n",
    "model_params = {\n",
    "    \"K\": 10, \n",
    "    \"num_layers\":2, \n",
    "    \"input_dim\":1, \n",
    "    \"output_dim\":10, \n",
    "    \"hidden_dim\":10,\n",
    "}\n",
    "\n",
    "\n",
    "model = get_model(model_name, model_params, device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.nll_loss\n",
    "mnist_metrics = {\"mnist_acc\": Accuracy()}\n",
    "rot_mnist_metrics = {\"rot_mnist_acc\": Accuracy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ignite's engines\n",
    "trainer = create_supervised_trainer(model, optimizer, loss_fn, device, prepare_batch=prepare_batch)\n",
    "ProgressBar(persist=False, desc=\"Training\").attach(trainer)\n",
    "\n",
    "mnist_evaluator = create_supervised_evaluator(model, mnist_metrics, device, prepare_batch=prepare_batch)\n",
    "ProgressBar(persist=False, desc=\"Evaluation\").attach(mnist_evaluator)\n",
    "\n",
    "rot_mnist_evaluator = create_supervised_evaluator(model, rot_mnist_metrics, device, prepare_batch=prepare_batch)\n",
    "ProgressBar(persist=False, desc=\"Evaluation\").attach(rot_mnist_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track training with wandb\n",
    "_ = trainer.add_event_handler(Events.ITERATION_COMPLETED, track_loss)\n",
    "_ = trainer.add_event_handler(Events.EPOCH_COMPLETED, track_metrics, mnist_evaluator, test_mnist_loader, \"test mnist\")\n",
    "_ = trainer.add_event_handler(Events.EPOCH_COMPLETED, track_metrics, rot_mnist_evaluator, test_rotated_mnist_loader, \"test_rotated_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model handler\n",
    "models_path = \"models\"\n",
    "eval_to_save = {\"model\": model}\n",
    "best_handler = Checkpoint(\n",
    "    eval_to_save,\n",
    "    DiskSaver(models_path, create_dir=True, require_empty=False),\n",
    "    n_saved=1,\n",
    "    filename_prefix=f\"best-{model_name}\",\n",
    "    score_function=lambda engine: engine.state.metrics[\"mnist_acc\"],\n",
    "    score_name=\"mnist_acc\",\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "_ = mnist_evaluator.add_event_handler(Events.COMPLETED, best_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "max_epochs = 20\n",
    "trainer.run(train_mnist_loader, max_epochs=max_epochs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
