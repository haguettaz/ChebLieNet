{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb\n",
    "\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.handlers import Checkpoint, DiskSaver, global_step_from_engine\n",
    "from ignite.metrics import Accuracy\n",
    "\n",
    "from gechebnet.data.dataloader import get_datalist_mnist, get_datalist_rotated_mnist, get_dataloader\n",
    "from gechebnet.data.dataset import download_mnist, download_rotated_mnist\n",
    "from gechebnet.graph.graph import GraphData\n",
    "from gechebnet.model.model import get_model\n",
    "from gechebnet.utils import prepare_batch, track_loss, track_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"gechebnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download mnist and rotated mnist\n",
    "data_path = \"data\"\n",
    "mnist_processed_path = download_mnist(data_path)\n",
    "rotated_mnist_processed_path = download_rotated_mnist(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the graph embedding data\n",
    "eps = .25\n",
    "xi = .01\n",
    "nx, ny, nz = (28, 28, 6)\n",
    "graph_data = GraphData(grid_size=(nx, ny), \n",
    "                       num_layers=nz,\n",
    "                       static_compression=(\"edge\", 0.5),\n",
    "                       self_loop=True, \n",
    "                       weight_threshold=0.3, \n",
    "                       sigma=1., \n",
    "                       lambdas=((xi/eps), xi, 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training dataloader from mnist\n",
    "train_mnist_loader = get_dataloader(\n",
    "    get_datalist_mnist(graph_data, mnist_processed_path, train=True), \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test dataloader from mnist\n",
    "test_mnist_loader = get_dataloader(\n",
    "    get_datalist_mnist(graph_data, mnist_processed_path, train=False), \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test dataloader from rotated mnist\n",
    "test_rotated_mnist_loader = get_dataloader(\n",
    "    get_datalist_rotated_mnist(graph_data, rotated_mnist_processed_path, train=False), \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"chebnet\"\n",
    "model_params = {\n",
    "    \"K\": 10, \n",
    "    \"num_layers\":2, \n",
    "    \"input_dim\":1, \n",
    "    \"output_dim\":10, \n",
    "    \"hidden_dim\":10,\n",
    "}\n",
    "\n",
    "\n",
    "model = get_model(model_name, model_params, device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.nll_loss\n",
    "mnist_metrics = {\"mnist_acc\": Accuracy()}\n",
    "rot_mnist_metrics = {\"rot_mnist_acc\": Accuracy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ignite's engines\n",
    "trainer = create_supervised_trainer(model, optimizer, loss_fn, device, prepare_batch=prepare_batch)\n",
    "ProgressBar(persist=False, desc=\"Training\").attach(trainer)\n",
    "\n",
    "mnist_evaluator = create_supervised_evaluator(model, mnist_metrics, device, prepare_batch=prepare_batch)\n",
    "ProgressBar(persist=False, desc=\"Evaluation\").attach(mnist_evaluator)\n",
    "\n",
    "rot_mnist_evaluator = create_supervised_evaluator(model, rot_mnist_metrics, device, prepare_batch=prepare_batch)\n",
    "ProgressBar(persist=False, desc=\"Evaluation\").attach(rot_mnist_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track training with wandb\n",
    "_ = trainer.add_event_handler(Events.ITERATION_COMPLETED, track_loss)\n",
    "_ = trainer.add_event_handler(Events.EPOCH_COMPLETED, track_metrics, mnist_evaluator, test_mnist_loader, \"test mnist\")\n",
    "_ = trainer.add_event_handler(Events.EPOCH_COMPLETED, track_metrics, rot_mnist_evaluator, test_rotated_mnist_loader, \"test_rotated_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model handler\n",
    "models_path = \"models\"\n",
    "eval_to_save = {\"model\": model}\n",
    "best_handler = Checkpoint(\n",
    "    eval_to_save,\n",
    "    DiskSaver(models_path, create_dir=True, require_empty=False),\n",
    "    n_saved=1,\n",
    "    filename_prefix=f\"best-{model_name}\",\n",
    "    score_function=lambda engine: engine.state.metrics[\"mnist_acc\"],\n",
    "    score_name=\"mnist_acc\",\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "_ = mnist_evaluator.add_event_handler(Events.COMPLETED, best_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "max_epochs = 20\n",
    "trainer.run(train_mnist_loader, max_epochs=max_epochs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
