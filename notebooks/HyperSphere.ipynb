{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = [84.72, 86.72, 88.83, 86.28, 84.28]\n",
    "aniso = [87.46, 80.67, 76, 77.56, 72.91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(iso), np.std(iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(aniso), np.std(aniso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeops\n",
    "import torch\n",
    "import math\n",
    "from pykeops.torch import LazyTensor\n",
    "\n",
    "device = 'cpu' \n",
    "\n",
    "# rounds to the nearest integer (0 decimal)\n",
    "x = torch.FloatTensor(1000, 1).uniform_(-10, 10)\n",
    "y = x.data.clone()\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "x.requires_grad = True\n",
    "y.requires_grad = True\n",
    "\n",
    "x_i = LazyTensor(x[:, None])\n",
    "s1 = x_i.round(0).sum(0)\n",
    "s2 = torch.sum(torch.round(y))\n",
    "print(\"s1 - s2\", torch.abs(s1 - s2).item())\n",
    "assert torch.abs(s1 - s2) < 1e-3, torch.abs(s1 - s2)\n",
    "\n",
    "s1.backward()\n",
    "s2.backward()\n",
    "\n",
    "print(\"grad_s1 - grad_s2\", torch.max(torch.abs(x.grad - y.grad)).item())\n",
    "assert torch.max(torch.abs(x.grad - y.grad)) < 1e-3\n",
    "\n",
    "# rounds to 3 decimal places\n",
    "x = torch.FloatTensor(1000, 1).uniform_(-1, 1)\n",
    "y = x.data.clone()\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "x.requires_grad = True\n",
    "y.requires_grad = True\n",
    "\n",
    "x_i = LazyTensor(x[:, None])\n",
    "s1 = x_i.round(3).sum(0)\n",
    "s2 = torch.sum(torch.round(y * 1e3)*1e-3)\n",
    "print(\"s1 - s2\", torch.abs(s1 - s2).item())\n",
    "assert torch.abs(s1 - s2) < 1e-3, torch.abs(s1 - s2)\n",
    "\n",
    "s1.backward()\n",
    "s2.backward()\n",
    "\n",
    "print(\"grad_s1 - grad_s2\", torch.max(torch.abs(x.grad - y.grad)).item())\n",
    "assert torch.max(torch.abs(x.grad - y.grad)) < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-1, 1, 100)\n",
    "plt.scatter(x, torch.acos(x), s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 3.14159, 100)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x, 1 - torch.heaviside(x - 3.14159, torch.ones(1)), s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.nn.Identity()\n",
    "x = torch.rand(16, 3, 100)\n",
    "torch.allclose(x, l(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_divide(vertices, faces, level):\n",
    "    vertices /= torch.norm(vertices, dim=1, keepdim=True)\n",
    "    for _ in range(level):\n",
    "        sub_faces = torch.stack((faces[:, [0, 1, 2]], faces[:, [2, 0, 1]], faces[:, [1, 2, 0]]), dim=1)\n",
    "        vertices_1 = vertices[sub_faces[:, :, [0, 1]]].mean(dim=2)\n",
    "        vertices_1 /= torch.norm(vertices_1, dim=2, keepdim=True)\n",
    "        vertices_2 = vertices[sub_faces[:, :, [1, 2]]].mean(dim=2)\n",
    "        vertices_2 /= torch.norm(vertices_2, dim=2, keepdim=True)\n",
    "        \n",
    "        N = vertices.shape[0]\n",
    "        NV1 = vertices_1.shape[0]*vertices_1.shape[1]\n",
    "        NV2 = vertices_2.shape[0]*vertices_1.shape[1]\n",
    "        \n",
    "        sub_faces[:,:,0] = torch.arange(N, N+NV1).reshape(-1, 3)\n",
    "        sub_faces[:,:,2] = torch.arange(N+NV1, N+NV1+NV2).reshape(-1, 3)\n",
    "        \n",
    "        faces = torch.cat((sub_faces, torch.arange(N, N+NV1).reshape(-1,1, 3)), dim=1).reshape(-1, 3)\n",
    "        vertices = torch.cat((vertices, vertices_1.reshape(-1, 3), vertices_2.reshape(-1, 3)), dim=0)\n",
    "        \n",
    "    return vertices.unique(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz2betagamma(x, y, z):\n",
    "    \"\"\"\n",
    "    Returns new tensors corresponding to angle representation from the cartesian representation.\n",
    "\n",
    "    Args:\n",
    "        x (FloatTensor): input tensor, i.e. x positions.\n",
    "        y (FloatTensor): input tensor, i.e. y positions.\n",
    "        z (FloatTensor): input tensor, i.e. z positions.\n",
    "\n",
    "    Returns:\n",
    "        (FloatTensor): output tensor, i.e. alpha rotation about x axis.\n",
    "        (FloatTensor): output tensor, i.e. beta rotation about y axis.\n",
    "        (FloatTensor): output tensor, i.e. gamma rotation about z axis.\n",
    "    \"\"\"\n",
    "\n",
    "    beta = torch.stack(\n",
    "        (\n",
    "            torch.atan2(-z, -torch.sqrt(x.pow(2) + y.pow(2))),\n",
    "            torch.atan2(-z, torch.sqrt(x.pow(2) + y.pow(2))),\n",
    "        ),\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    gamma = torch.stack((torch.atan2(-y, -x), torch.atan2(y, x)), dim=-1)\n",
    "\n",
    "    mask = (beta >= -math.pi) & (beta < math.pi) & (gamma >= -math.pi/2) & (gamma < math.pi/2)\n",
    "    \n",
    "    return beta[mask], gamma[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetrahedron_vertices = torch.tensor([[1, 0, -1/math.sqrt(2)],[-1, 0, -1/math.sqrt(2)], \n",
    "                                     [0, 1, 1/math.sqrt(2)],[0, -1, 1/math.sqrt(2)]])\n",
    "tetrahedron_faces = torch.tensor([[0, 1, 2], [0, 2, 3], [0, 1, 3], [1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octahedron_vertices = torch.tensor([[1., 0., 0.], [0., 1., 0.], [-1., 0., 0.], \n",
    "                                    [0., -1., 0.], [0., 0., 1.], [0., 0., -1.]])\n",
    "octahedron_faces = torch.tensor([[0, 1, 5], [1, 5, 2], [2, 5, 3], [0, 5, 3], \n",
    "                                 [0, 3, 4], [0, 1, 4], [1, 2, 4], [2, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = (1 + math.sqrt(5))/2\n",
    "\n",
    "icosahedron_vertices = torch.tensor([[phi, 1., 0.], [-phi, 1., 0.], [phi, -1., 0.], [-phi, -1., 0.],\n",
    "                                     [1., 0., phi], [1., 0., -phi], [-1., 0., phi], [-1., 0., -phi],\n",
    "                                     [0., phi, 1.], [0., -phi, 1.], [0., phi, -1.], [0., -phi, -1.]])\n",
    "icosahedron_faces = torch.tensor([[0, 2, 4], [0, 2, 5], [0, 4, 8], [0, 8, 10], [0, 5, 10],\n",
    "                                  [1, 3, 6], [1, 3, 7], [1, 6, 8], [1, 7, 10], [1, 8, 10],\n",
    "                                  [2, 4, 9], [2, 5, 11], [2, 9, 11], [3, 7, 11], [3, 9, 11],\n",
    "                                  [3, 6, 9], [4, 6, 9], [4, 6, 8], [5, 7, 10], [5, 7, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sub_divide(icosahedron_vertices, icosahedron_faces, 5)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, gamma = xyz2betagamma(X[:,0],X[:,1],X[:,2])\n",
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8.0, 8.0))\n",
    "\n",
    "ax = fig.add_subplot(\n",
    "    111,\n",
    "    projection=\"3d\",\n",
    "    xlim=(-1., 1.),\n",
    "    ylim=(-1., 1.),\n",
    "    zlim=(-1., 1.)\n",
    ")\n",
    "\n",
    "im = ax.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    X[:, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "dist = (X.unsqueeze(0) - X.unsqueeze(1)).pow(2).sum(dim=2) + 100 * torch.eye(N, N).bool()\n",
    "min_, _ = dist.min(dim=0)\n",
    "\n",
    "_ = plt.hist(min_, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repulsive_sampling(num_samples, loss_fn, device, max_iter=10000):\n",
    "    lr = 1e-2\n",
    "\n",
    "    X = torch.FloatTensor(num_samples, 3).uniform_(-1, 1)\n",
    "    X = X.to(device)\n",
    "    X.requires_grad_()\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        loss = rejection_loss(X, 1., 10.)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X -= lr * X.grad\n",
    "            X.grad.zero_()\n",
    "\n",
    "    X = X.detach().cpu()   \n",
    "    X /= X.norm(dim=1, keepdim=True)\n",
    "    \n",
    "    return X[:,0], X[:,1], X[:,2]\n",
    "\n",
    "def rejection_loss(x, alpha=1., beta=1.):\n",
    "    N = x.shape[0]\n",
    "    dist = (x.unsqueeze(0) - x.unsqueeze(1)).pow(2).sum(dim=2) + 1000 * torch.eye(N, N).to(x.device)   \n",
    "    return alpha*(1/dist).mean() + beta*torch.abs(1. - x.norm(dim=1)).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz2betagamma(x, y, z):           \n",
    "    beta = torch.stack(\n",
    "        (\n",
    "            torch.atan2(-z, torch.sqrt(x.pow(2) + y.pow(2))), \n",
    "            torch.atan2(-z, torch.sqrt(x.pow(2) + y.pow(2))), \n",
    "        ),\n",
    "        dim=1\n",
    "    )\n",
    "    \n",
    "    gamma = torch.stack(\n",
    "        (\n",
    "            torch.atan2(-y, -x), \n",
    "            torch.atan2(y, x), \n",
    "        ),\n",
    "        dim=1\n",
    "    )\n",
    "            \n",
    "    mask = (-math.pi <= beta) & (beta < math.pi) & (-math.pi/2 <= gamma) & ( gamma < math.pi/2)\n",
    "                        \n",
    "    return beta[mask], gamma[mask]\n",
    "\n",
    "def betagamma2xyz(beta, gamma):\n",
    "    alpha, beta, gamma = alphabetagamma[:, 0], alphabetagamma[:, 1], alphabetagamma[:, 2]    \n",
    "    x = (1 + alpha) * torch.cos(beta) * torch.cos(gamma) \n",
    "    y = (1 + alpha) * torch.cos(beta) * torch.sin(gamma) \n",
    "    z = -(1 + alpha) * torch.sin(beta)\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz2alphabetagamma(x, y, z):\n",
    "\n",
    "    alpha = torch.sqrt(x.pow(2) + y.pow(2) + z.pow(2)) - math.pi\n",
    "\n",
    "    beta = torch.stack(\n",
    "        (\n",
    "            torch.atan2(-z, -torch.sqrt(x.pow(2) + y.pow(2))),\n",
    "            torch.atan2(-z, torch.sqrt(x.pow(2) + y.pow(2))),\n",
    "        ),\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    gamma = torch.stack((torch.atan2(-y, -x), torch.atan2(y, x)), dim=-1)\n",
    "\n",
    "    mask = (beta >= -math.pi) & (beta < math.pi) & (gamma >= -math.pi/2) & (gamma < math.pi/2)\n",
    "\n",
    "    return alpha, beta[mask], gamma[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "x = torch.tensor([-1.])\n",
    "y = torch.tensor([0.])\n",
    "z = torch.tensor([0.])\n",
    "\n",
    "xyz2alphabetagamma(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = lambda x: -1 if x < 0. else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.tan(math.fabs(math.pi/2 - beta/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sgn(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = -math.pi/3\n",
    "gamma = -math.pi/2\n",
    "x = gamma\n",
    "y = - 4 * math.tan(beta/4)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.log(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.\n",
    "x = gamma\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nalpha = 2\n",
    "\n",
    "alpha = torch.arange(0.0, math.pi, math.pi / nalpha).unsqueeze(1).repeat(1, 3)\n",
    "\n",
    "xyz = (X.unsqueeze(1) * (1 + alpha.unsqueeze(0))).reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabetagamma = xyz2alphabetagamma(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(xyz, alphabetagamma2xyz(alphabetagamma), atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_loss(x, alpha=1., beta=1.):\n",
    "    N = x.shape[0]\n",
    "    \n",
    "    dist = (x.unsqueeze(0) - x.unsqueeze(1)).pow(2).sum(dim=2) + 1000 * torch.eye(N, N).to(x.device)\n",
    "        \n",
    "    norm = x.norm(dim=1)\n",
    "    \n",
    "    return alpha*(1/dist).mean() + beta*torch.abs(1. - norm).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8.0, 8.0))\n",
    "\n",
    "ax = fig.add_subplot(\n",
    "    111,\n",
    "    projection=\"3d\",\n",
    "    xlim=(-1., 1.),\n",
    "    ylim=(-1., 1.),\n",
    "    zlim=(-1., 1.)\n",
    ")\n",
    "\n",
    "im = ax.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    X[:, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercator projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mercator_projection(beta, gamma, images):\n",
    "    ix = beta\n",
    "    iy = torch.log(torch.tan(gamma/2 + math.pi/4))\n",
    "    \n",
    "    ix_ = (ix - ix.min())/(ix.max()-ix.min())\n",
    "    iy_ = (iy - iy.min())/(iy.max()-iy.min())\n",
    "    \n",
    "    ix_inf = ix_.floor().long()\n",
    "    ix_sup = ix_.ceil().long()\n",
    "    iy_inf = iy_.floor().long()\n",
    "    iy_sup = iy_.ceil().long()\n",
    "    \n",
    "    return (images[:,:,ix_inf, iy_inf] + images[:,:,ix_sup, iy_sup])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "nalpha = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = repulsive_spherical_sampling(num_samples, torch.device(\"cuda\"), 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, gamma = xyz2betagamma(x, y, z)\n",
    "alpha = torch.arange(0.0, math.pi, math.pi / nalpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pos = torch.stack(\n",
    "    (\n",
    "        beta.unsqueeze(0).expand(nalpha, num_samples).flatten(), \n",
    "        gamma.unsqueeze(0).expand(nalpha, num_samples).flatten(), \n",
    "        alpha.unsqueeze(1).expand(nalpha, num_samples).flatten()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(10, 3, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mercator_projection(beta, gamma, img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.repeat(1, 1, nalpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8.0, 8.0))\n",
    "\n",
    "ax = fig.add_subplot(\n",
    "    111,\n",
    "    projection=\"3d\",\n",
    ")\n",
    "\n",
    "im = ax.scatter(\n",
    "    x, \n",
    "    y,\n",
    "    z,\n",
    "    c = img[0,0,0:100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8.0, 8.0))\n",
    "\n",
    "ax = fig.add_subplot(\n",
    "    111,\n",
    "    projection=\"3d\",\n",
    ")\n",
    "\n",
    "im = ax.scatter(\n",
    "    x, \n",
    "    y,\n",
    "    z,\n",
    "    c = img[0, 0, 100:200]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*100*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(100000,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x.unsqueeze(0) - x.unsqueeze(1)).pow(2).sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit (x[0] - x[1:]).pow(2).sum(dim=1).topk(32, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RX = torch.tensor([\n",
    "                [1, 0, 0],\n",
    "                [0, cos(roll), -sin(roll)],\n",
    "                [0, sin(roll), cos(roll)]\n",
    "            ],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrice(theta, axis):\n",
    "    cos = torch.cos(theta)\n",
    "    sin = torch.sin(theta)\n",
    "    \n",
    "    if axis == 0:\n",
    "        return torch.tensor([\n",
    "                [1, 0, 0],\n",
    "                [0, cos, -sin],\n",
    "                [0, sin, cos]\n",
    "            ])\n",
    "    \n",
    "    if axis == 1:\n",
    "        return torch.tensor([\n",
    "                [cos, 0, sin],\n",
    "                [0, 0, 0],\n",
    "                [-sin, 0, cos]\n",
    "            ])\n",
    "    \n",
    "    if axis == 2:\n",
    "        return torch.tensor([\n",
    "                [cos, -sin, 0],\n",
    "                [sin, cos, 0],\n",
    "                [0, 0, 0]\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.rand(100)\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_matrice(theta, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[0., -1., 5.],[1., 0., 8.],[0., 0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se2group2matrix(g):\n",
    "    N, D = g.shape\n",
    "    \n",
    "    cos = torch.cos(g[:,2])\n",
    "    sin = torch.sin(g[:,2])\n",
    "    \n",
    "    Gg = torch.zeros(N, D, D)\n",
    "    Gg[:, 0, 0] = cos\n",
    "    Gg[:, 0, 1] = - sin\n",
    "    Gg[:, 0, 2] = g[:,0]\n",
    "    Gg[:, 1, 0] = sin\n",
    "    Gg[:, 1, 1] = cos\n",
    "    Gg[:, 1, 2] = g[:,1]\n",
    "    Gg[:, 2, 2] = 1.\n",
    "\n",
    "def matrix2se2group(Gg):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_log(A, max_order=10):\n",
    "    D = A.shape[-1]\n",
    "    A = A - torch.eye(D)\n",
    "    Ak = A.clone()\n",
    "    \n",
    "    M = torch.zeros(A.shape)\n",
    "        \n",
    "    for k in range(1, max_order):\n",
    "        Ak = torch.matmul(Ak, A)\n",
    "        if k % 2:\n",
    "            M += Ak/k\n",
    "        else:\n",
    "            M -= Ak/k\n",
    "            \n",
    "        print(Ak, M)\n",
    "            \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(100, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, vec = torch.eig(a, eigenvectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import logm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = math.pi\n",
    "x = 1\n",
    "y = 1\n",
    "\n",
    "a = torch.tensor([\n",
    "    [math.cos(theta), -math.sin(theta), x],\n",
    "    [math.sin(theta), math.cos(theta), y],\n",
    "    [0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "logm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = torch.log(torch.complex(val[:,0], val[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vec = torch.complex(vec[:,1], vec[:,2])\n",
    "true_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.complex(vec, torch.zeros(vec.shape)) @ log @ torch.complex(vec, torch.zeros(vec.shape)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_log(a, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[-1.,  1.,  5.],\n",
    "        [-1., -1.,  8.],\n",
    "        [ 0.,  0.,  0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a @ a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tensor = torch.rand(100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = tensor[:, [0,1,2]]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
